library(C50)
data(churn)
str(churnTrain)
churnTrain = churnTrain[,! names(churnTrain) %in% c("state","area_code", "account_length") ]
set.seed(2)
ind = sample(2, nrow(churnTrain), replace = TRUE, prob=c(0.7,0.3))
trainset = churnTrain[ind == 1,]
testset = churnTrain[ind == 2,]
svm.model= train(churn ~ .,data = trainset,method = "svmRadial")
svm.pred = predict(svm.model, testset[,! names(testset) %in% c("churn")])
table(svm.pred, testset[,c("churn")])
confusionMatrix(svm.pred, testset[,c("churn")])
install.packages("ROCR")
library(ROCR)
svmfit=svm(churn~ ., data=trainset, prob=TRUE)
svmfit
pred=predict(svmfit,testset[, !names(testset) %in% c("churn")], probability=TRUE)
pred.prob = attr(pred, "probabilities")
pred.to.roc = pred.prob[, 2]
pred.rocr = prediction(pred.to.roc, testset$churn)
perf.rocr = performance(pred.rocr, measure = "auc", x.measure ="cutoff")
svmfit=svm(churn~ ., data=trainset, prob=TRUE)
pred=predict(svmfit,testset[, !names(testset) %in% c("churn")], probability=TRUE)
pred
pred.prob = attr(pred, "probabilities")
pred.prob
pred.to.roc = pred.prob[, 2]
pred.to.roc
plot(perf.tpr.rocr, colorize=T,main=paste("AUC:",(perf.rocr@y.values)))
library(rpart)
plot(perf.tpr.rocr, colorize=T,main=paste("AUC:",(perf.rocr@y.values)))
perf.tpr.rocr = performance(pred.rocr, "tpr","fpr")
plot(perf.tpr.rocr, colorize=T,main=paste("AUC:",(perf.rocr@y.values)))
Qoo = read.table("ingre_dups.txt",sep=",")
library(dplyr)
str(Qoo)
Qoo$V3 = as.integer(as.character(Qoo$V3))
Qoo$V4 = as.integer(as.character(Qoo$V4))
Qxx = Qoo %>%
group_by(V1) %>%
summarise(WeightMean = mean(V3,na.rm = T),
KalMean = mean(V4, na.rm = T),
PerGramMean = mean(V5, na.rm = T))
write.table(Qxx, "ingre_dups1.txt",sep=",",quote = F, row.names = F,
col.names = F)
Qyy =
select(Qoo, V1, V2) %>%
filter(V2 != '') %>%
distinct(V1,V2)
write.table(Qxx, "ingre_units.txt",sep=",",quote = F, row.names = F,
col.names = F)
write.table(inner_join(X, Y), "joined.txt",sep=",",quote = F, row.names = F,
col.names = F)
Qoo = read.table("ingre_dups.txt",sep=",")
library(dplyr)
str(Qoo)
Qoo$V3 = as.integer(as.character(Qoo$V3))
Qoo$V4 = as.integer(as.character(Qoo$V4))
Qxx = Qoo %>%
group_by(V1) %>%
summarise(WeightMean = mean(V3,na.rm = T),
KalMean = mean(V4, na.rm = T),
PerGramMean = mean(V5, na.rm = T))
write.table(Qxx, "ingre_dups1.txt",sep=",",quote = F, row.names = F,
col.names = F)
Qyy =
select(Qoo, V1, V2) %>%
filter(V2 != '') %>%
distinct(V1,V2)
write.table(Qxx, "ingre_units.txt",sep=",",quote = F, row.names = F,
col.names = F)
write.table(inner_join(Qxx, Qyy), "joined.txt",sep=",",quote = F, row.names = F,
col.names = F)
Qxx =
Qoo %>%
group_by(V1) %>%
summarise(WeightMean = mean(V3,na.rm = T),
KalMean = mean(V4, na.rm = T),
PerGramMean = mean(V5, na.rm = T))
Qoo = read.table("ingre_dups.txt",sep=",")
setwd("~/GitHub/marketingtaiwan/熱量食材check")
Qoo = read.table("ingre_dups.txt",sep=",")
library(dplyr)
str(Qoo)
Qoo$V3 = as.integer(as.character(Qoo$V3))
Qoo$V4 = as.integer(as.character(Qoo$V4))
Qxx =
Qoo %>%
group_by(V1) %>%
summarise(WeightMean = mean(V3,na.rm = T),
KalMean = mean(V4, na.rm = T),
PerGramMean = mean(V5, na.rm = T))
write.table(Qxx, "ingre_dups1.txt",sep=",",quote = F, row.names = F,
col.names = F)
Qyy =
select(Qoo, V1, V2) %>%
filter(V2 != '') %>%
distinct(V1,V2)
write.table(Qxx, "ingre_units.txt",sep=",",quote = F, row.names = F,
col.names = F)
write.table(inner_join(Qxx, Qyy), "joined.txt",sep=",",quote = F, row.names = F,
col.names = F)
